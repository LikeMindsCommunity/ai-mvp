{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-genai\n",
      "  Downloading google_genai-1.9.0-py3-none-any.whl.metadata (32 kB)\n",
      "Collecting anyio<5.0.0,>=4.8.0 (from google-genai)\n",
      "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth<3.0.0,>=2.14.1 (from google-genai)\n",
      "  Using cached google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting httpx<1.0.0,>=0.28.1 (from google-genai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting pydantic<3.0.0,>=2.0.0 (from google-genai)\n",
      "  Downloading pydantic-2.11.1-py3-none-any.whl.metadata (63 kB)\n",
      "Collecting requests<3.0.0,>=2.28.1 (from google-genai)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting websockets<15.1.0,>=13.0.0 (from google-genai)\n",
      "  Using cached websockets-15.0.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting typing-extensions<5.0.0,>=4.11.0 (from google-genai)\n",
      "  Using cached typing_extensions-4.13.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting idna>=2.8 (from anyio<5.0.0,>=4.8.0->google-genai)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting sniffio>=1.1 (from anyio<5.0.0,>=4.8.0->google-genai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0.0,>=2.14.1->google-genai)\n",
      "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0,>=2.14.1->google-genai)\n",
      "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.0,>=2.14.1->google-genai)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting certifi (from httpx<1.0.0,>=0.28.1->google-genai)\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1.0.0,>=0.28.1->google-genai)\n",
      "  Using cached httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.0.0->google-genai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.0 (from pydantic<3.0.0,>=2.0.0->google-genai)\n",
      "  Using cached pydantic_core-2.33.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.0.0->google-genai)\n",
      "  Using cached typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3.0.0,>=2.28.1->google-genai)\n",
      "  Using cached charset_normalizer-3.4.1-cp313-cp313-macosx_10_13_universal2.whl.metadata (35 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3.0.0,>=2.28.1->google-genai)\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Downloading google_genai-1.9.0-py3-none-any.whl (149 kB)\n",
      "Using cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Using cached google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Downloading pydantic-2.11.1-py3-none-any.whl (442 kB)\n",
      "Using cached pydantic_core-2.33.0-cp313-cp313-macosx_11_0_arm64.whl (1.9 MB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached typing_extensions-4.13.0-py3-none-any.whl (45 kB)\n",
      "Using cached websockets-15.0.1-cp313-cp313-macosx_11_0_arm64.whl (173 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp313-cp313-macosx_10_13_universal2.whl (195 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: websockets, urllib3, typing-extensions, sniffio, pyasn1, idna, h11, charset-normalizer, certifi, cachetools, annotated-types, typing-inspection, rsa, requests, pydantic-core, pyasn1-modules, httpcore, anyio, pydantic, httpx, google-auth, google-genai\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.9.0 cachetools-5.5.2 certifi-2025.1.31 charset-normalizer-3.4.1 google-auth-2.38.0 google-genai-1.9.0 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 idna-3.10 pyasn1-0.6.1 pyasn1-modules-0.4.2 pydantic-2.11.1 pydantic-core-2.33.0 requests-2.32.3 rsa-4.9 sniffio-1.3.1 typing-extensions-4.13.0 typing-inspection-0.4.0 urllib3-2.3.0 websockets-15.0.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "def get_md_files(directory):\n",
    "    md_files = []\n",
    "    # Get all .md files in current directory\n",
    "    md_files.extend(glob.glob(os.path.join(directory, '*.md')))\n",
    "    # Look for subdirectories\n",
    "    for item in os.listdir(directory):\n",
    "        item_path = os.path.join(directory, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            # Recursively get .md files from subdirectories\n",
    "            md_files.extend(get_md_files(item_path))\n",
    "    return md_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "\n",
    "def generate():\n",
    "    prompt_content=\"\"\n",
    "    client = genai.Client(\n",
    "        api_key=os.environ.get(\"GEMINI_API_KEY\"),\n",
    "    )\n",
    "\n",
    "    with open('prompt.txt', 'r') as file:\n",
    "        prompt_content = file.read()\n",
    "    \n",
    "    docs_path = 'docs/chat'\n",
    "    markdown_files = get_md_files(docs_path)\n",
    "    \n",
    "    # Format the list of files for output\n",
    "    file_list = []\n",
    "    for file_path in markdown_files:\n",
    "        relative_path = os.path.relpath(file_path, docs_path)\n",
    "        file_list.append(relative_path)\n",
    "\n",
    "\n",
    "    model = \"gemini-2.5-pro-exp-03-25\"\n",
    "    contents = [\n",
    "        types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[\n",
    "                types.Part.from_text(text=\"\"\"How do I integrate LikeMinds Chat SDK in Flutter?\"\"\"),\n",
    "            ],\n",
    "        ),\n",
    "    ]\n",
    "    tools = [\n",
    "        types.Tool(\n",
    "            function_declarations=[\n",
    "                types.FunctionDeclaration(\n",
    "                    name=\"fetch_documents\",\n",
    "                    description=\"Fetches the documentation needed for the context, given the tech stack\",\n",
    "                    parameters=types.FunctionParameters(\n",
    "                        properties={\n",
    "                            \"tech_stack\": types.Property(\n",
    "                                description=\"The tech stack of the project\",\n",
    "                                type=\"string\",\n",
    "                            ),\n",
    "                        },\n",
    "                    ),\n",
    "                    response=types.FunctionResponse(\n",
    "                        mime_type=\"text/plain\",\n",
    "                        parts=[\n",
    "                            types.Part.from_text(text=\"\"\"INSERT_RESPONSE_HERE\"\"\"),\n",
    "                        ],\n",
    "                    ),\n",
    "                ),\n",
    "            ],\n",
    "        ),\n",
    "    ]\n",
    "    generate_content_config = types.GenerateContentConfig(\n",
    "        tools=tools,\n",
    "        response_mime_type=\"text/plain\",\n",
    "        system_instruction=[\n",
    "            types.Part.from_text(text=\"\"\"You are a helpful integration assistant from LikeMinds, which is a company that makes Chat and Feed SDKs in multiple tech stacks (React, React Native, Flutter, Android, and iOS). You are an expert at preparing solutions and integration guides and runnable code in all our supported SDKs. You have access to our documentation which details how everything is supposed to be done. Do not hallucinate any information, provide clear and concise steps.\"\"\"),\n",
    "            types.Part.from_text(text=prompt_content)\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    for chunk in client.models.generate_content_stream(\n",
    "        model=model,\n",
    "        contents=contents,\n",
    "        config=generate_content_config,\n",
    "    ):\n",
    "        print(chunk.text if not chunk.function_calls else chunk.function_calls[0])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
